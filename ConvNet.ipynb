{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A single convolution network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt \n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    @staticmethod\n",
    "    def activation(z):\n",
    "        z[z < 0] = 0\n",
    "        return z\n",
    "    \n",
    "    @staticmethod\n",
    "    def derivative(z):\n",
    "        z[z < 0] = 0\n",
    "        z[z > 0] = 1\n",
    "        return z\n",
    "        \n",
    "class Sigmoid:\n",
    "    @staticmethod\n",
    "    def activation(z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    @staticmethod\n",
    "    def derivative(z):\n",
    "        return Sigmoid.activation(z) * (1 - Sigmoid.activation(z))\n",
    "    \n",
    "class MSE:\n",
    "    def __init__(self, activation_fn=None):\n",
    "        self.activation_fn = activation_fn\n",
    "            \n",
    "    def activation(self, z):\n",
    "        return self.activation_fn.activation(z)\n",
    "\n",
    "    @staticmethod\n",
    "    def loss(y_true, y_pred):\n",
    "        return np.mean((y_pred - y_true)**2)\n",
    "\n",
    "    @staticmethod\n",
    "    def derivative(y_true, y_pred):\n",
    "        return y_pred - y_true\n",
    "\n",
    "    def delta(self, y_true, y_pred):\n",
    "        return self.derivative(y_true, y_pred) * self.activation_fn.derivative(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv:\n",
    "    def __init__(self, kernel_size, pad=0, stride=1):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.filter = np.random.rand(self.kernel_size, self.kernel_size)\n",
    "        self.cache = None\n",
    "        self.pad = pad\n",
    "        self.stride = stride\n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''Forward pass with input x'''\n",
    "        \n",
    "        # Compute the output size assuming stride=1 and no padding\n",
    "        (h_x, w_x) = X.shape\n",
    "        h_o = int(1  + (h_x  +  2  *  self.pad  -  self.kernel_size))\n",
    "        w_o = int(1  + (w_x  +  2  *  self.pad  -  self.kernel_size))\n",
    "        \n",
    "        # Zero pad x\n",
    "        xp = np.pad(x , ((pad,), (pad,)), 'constant')\n",
    "\n",
    "        # Initialize the output with zeros        \n",
    "        out = np.zeros((h_o, w_o))\n",
    "    \n",
    "        # Convolution\n",
    "        for  i  in  range (h_o):\n",
    "            for  j  in  range (w_o):\n",
    "                for  k  in  range (self.kernel_size):\n",
    "                    for  l  in  range (self.kernel_size):\n",
    "                        out[i , j] +=  xp[self.stride * i + k , self.stride * j + l] *  self.filter[k , l]\n",
    "\n",
    "        # Saving information in 'cache' for backprop\n",
    "        self.cache = x\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        '''Backward pass with input as the gradient'''\n",
    "        \n",
    "        # Retrieving information from the \"cache\"\n",
    "        x = self.cache\n",
    "        (h, w) = x.shape\n",
    "\n",
    "        # Initializing dx, dw with the correct shapes\n",
    "        dx = np.zeros_like(x)\n",
    "        df = np.zeros_like(self.filter)\n",
    "        \n",
    "        # Retrieving dimensions from dout's shape\n",
    "        (h_o, w_o) = dout.shape\n",
    "\n",
    "        xp = np.pad(x, ((0,), (0,), (pad,), (pad, )), 'constant')\n",
    "        \n",
    "        # Calculate dw\n",
    "        for i in range(self.kernel_size):\n",
    "            for j in range(self.kernel_size):\n",
    "                for k in range():\n",
    "                    for l in range(W_):\n",
    "                        df[i,j] += xp[self.stride * i + k, self.stride * j + l] * dout[k, l]\n",
    "                        \n",
    "        doutp = np.pad(dout, ((self.kernel_size - 1,), (self.kernel_size - 1, )), 'constant')\n",
    "        dxp = np.pad(dx, ((pad,), (pad, )), 'constant')\n",
    "        \n",
    "        # Inverse the filter\n",
    "        f_ = np.zeros_like(self.filter)\n",
    "        for i in range(self.kernel_size):\n",
    "            for j in range(self.kernel_size):\n",
    "                f_[i,j] = self.filter[self.kernel_size - i - 1, self.kernel_size - j - 1]\n",
    "\n",
    "        # Calculate dx\n",
    "        for i in range(h + 2 * self.pad): \n",
    "            for j in range(w + 2 * self.pad):\n",
    "                for k in range(HH):\n",
    "                    for l in range(WW):\n",
    "                        dxp[i,j] += doutp[i + k, j + l] * f_[k, l]\n",
    "        \n",
    "        #Remove padding for dx\n",
    "        dx = dxp[pad:-pad, pad:-pad]\n",
    "        \n",
    "        self.update(df, learning_rate)\n",
    "        return dx, df\n",
    "    \n",
    "    def update(self, df, learning_rate):\n",
    "        self.filter -= learning_rate * df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
